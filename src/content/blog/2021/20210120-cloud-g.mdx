---
title: Cloud Gaming Setup
createdAt: 2021-01-20
description: Notes to self on cloud gaming
category: misc
---

import BlogPostToc from '../../../components/blog/BlogPostToc.astro'

## Contents

<BlogPostToc />

## Background

I am not an avid gamer, but I like to keep up on the state-of-the art in the game development industry. I believe the game industry drives a lot of futuristic tech. I only ever own and maintain a single laptop these days though. It's a relatively powerful laptop, with a discrete graphics card (GPU), but still not powerful enough to run modern games smoothly. I no longer want to build and maintain more physical computers than I absolutely must. I don't game enough to justify a dedicated gaming PC anyways, especially since they become obsolete so quickly.

Within the last couple years, remote servers with capable GPUs have started becoming available. Graphical remote control of servers has been possible for decades, but only recently has there been developments that allow remote control at extremely low latencies; Low enough to allow for even moderately fast games. That is the premise of "Cloud gaming", and you can read more about at it at places like [/r/cloudygamer/](https://www.reddit.com/r/cloudygamer/) . I believe it is the future, assuming Internet infrastructure continues to expand and bandwidth caps allow for it. Consider that there is no initial outlay for equipment that can quickly become obsolete. It is pay-for-use, provides access to higher end components, and can be accessed from anywhere using any device along as there is a decent Internet connection.

The industry titans see the potential (with different levels of commitment and execution):

- [NVidia GeForce NOW](https://www.nvidia.com/en-us/geforce-now/)
- [Google Stadia](https://stadia.google.com/)
- [Amazon Luna](https://www.amazon.com/luna/landing-page)
- [Microsoft Xbox Cloud](https://www.xbox.com/en-US/xbox-game-pass/cloud-gaming)

There are also some more interesting smaller players:

- [Shadow](https://shadow.tech/)
- [Paperspace](https://www.paperspace.com/core)
- [Parsec](https://parsec.app/)

## What I've Tried So Far

- [Nvidia GeForce NOW](https://www.nvidia.com/en-us/geforce-now/)
- [Paperspace](https://www.paperspace.com/core)
- [AWS G4 EC2 Instances](https://aws.amazon.com/ec2/instance-types/g4/) (DIY Setup)

With both Paperspace and AWS G4 setups, the magic component was the Parsec technology and client:

- [Parsec](https://parsec.app/)

### Parsec

In my experience so far, [Parsec](https://parsec.app/), has been an important component. Most remote desktop control solutions (including RDP and VNC) do not support low enough latencies to be useable for most games. When gaming, the display, audio, and input latencies are all important. Even when using Paperspace, which provides its own client, gaming wasn't smooth until I switched to using Parsec.

To setup Parsec on the AWS instance, I ran this script:

- [Parsec-Cloud-Preparation-Tool](https://github.com/parsec-cloud/Parsec-Cloud-Preparation-Tool)

That script seems to do a lot around common game requirement installs, including installing latest nVidia drivers (which have a licensing component when installed on cloud GPUs), MS DirectX Runtime, XBox controller drivers, Parsec itself, etc. It's dependent on external download locations though, and some of those are currently broken due. (i.e. MS XBox controller and DirectX runtimes.) I haven't yet fully looked in to exactly what Parsec is, everything this script does, licensing, or how stable the company is. I hope there are other alternatives, simply because if not, then I think they have a lock on what is possible and yet they don't seem to be overly robust.

### Nvidia GeForce NOW

I purchased an annual subscription to [Geforce NOW](https://www.nvidia.com/en-us/geforce-now/) early on (as a "founder"). That was before they started losing access to significant number of games, I assume due to publisher/developer greed.

- [Important test for the future of cloud gaming](https://www.theverge.com/2020/3/2/21161469/nvidia-geforce-now-cloud-gaming-service-developers-controversy-licensing)
- [Losing more games - but there's hope](https://www.techradar.com/news/nvidia-geforce-now-is-losing-more-games-but-theres-hope-for-the-future)

Because GeForce NOW only allows access to certain titles in my Steam library, I haven't used it much. For instance, there is no access to my copy of X-Plane (which I didn't purchase in Steam) and no support for MS Flight Simulator (which is not available on Steam). When I have used it, it worked reliably, but the quality did not strike me as being as good as my recent experiments using Parsec with Paperspace and AWS. However, there's no official way to install and use Parsec with Geforce NOW. Perhaps it has, or will, improve over time.

Also, due to the way it works, any game selected must first be redownloaded/reinstalled during startup. That takes a few minutes for larger games.

### Paperspace

[Paperspace](https://www.paperspace.com/core) is primarily marketing towards Machine Learning and similar professional GPU use cases. However, they do (or did?) have a convenience "template" for gaming which had Steam preinstalled, etc. It is much more convenient to create and use Paperspace machines than AWS EC2 instances. I don't think they had quite as powerful a GPU option as the latest AWS offerings, but it was sufficient.

Paperspace wasn't good for gaming purposes until I switched to using Parsec instead of the Paperspace client.

### AWS EC2 Instance (DIY)

AWS's latest [AWS G4 EC2 Instances](https://aws.amazon.com/ec2/instance-types/g4/) are quite powerful. However, setting up in AWS generally requires a lot of technical knowledge. I've been working with AWS for many years, and even so, AWS is constantly changing making it a consistent challenge. Two weeks ago I was able to request a spot G4 instance (at half the normal G4 hourly on-demand cost.) When I tried to do it yesterday, I was informed I could not because my account limits didn't allow for it. I had to wonder how was I able to do it two weeks ago? Turns out AWS is transitioning from "per instance limits" to "vCPU limits". There are old and new quota/limit interfaces in the AWS console simultaneously currently, and they don't seem to agree. Support doesn't seem to realize it. It took most of the day for them to approve my limit increase request. Luckily, I wasn't doing anything important.

This write-up by Richard Neil Ilagan provides a great overview and step-by-step of setting up an AWS instance with Parsec:

- [How to: Create a Remote Gaming Server using Parsec on AWS](https://www.richardneililagan.com/posts/create-game-server-aws-parsec#create-a-windows-based-ec2-instance)

Some changes:

- Spot instances no longer seem to be available to normal accounts (afaict...I'm not yet sure about this)
- G4 instances do not seem to be available without a vCPU limit increase request
- The parsec prep script throws errors trying to download certain items (but still seems to work)

Also, nVidia finally published an updated "NVIDIA Gaming PC - Windows Server 2019" AMI in the AWS Marketplace. It comes preinstalled with the lastest nVidia drivers already licensed, so the licensing step run by the Parsec script is not required.

## Costs

I haven't yet done much cost comparison. In general, I am expecting to pay ~$1.00/hr _while_ gaming, with a very small monthly charge for instance storage. That's a rough estimate, and the actuals can be significantly lower/higher depending on the setup and service. There are many factors that go in to the final cost, especially when using AWS.

One detail with Paperspace, is that while they do not charge a fee for stopped instances, they do have a fixed monthly charge for instance storage. I believe it was ~$5 or $7 per month. At first glance, I believe that is more expensive than AWS equivalent for someone like me that will only use it a couple hours or so a month. I probably only need ~60GB EBS, stored at ~$0.10/GB. However, there are so many other factors and a full cost comparison might show up differently. Minimally, the per hour costs depend on machine size and bandwidth usage.

Using AWS two weeks ago, I was able to get a `g4dn.2xlarge` (8 vCPU) as a spot instance with persistence setting. The persistence setting should have let me stop the instance when I was done using it to avoid additional charges, and then restart it whenever I wanted (assuming spot instances were available at my requested max price). It ended up that I was not able to restart due to changes in AWS limits and policy changes around spot instance handling for smaller accounts. When I had the spot instance, it was running about $0.50/hr. (There would also be some small bandwidth charges on top of that.) Now that I have to use on-demand instance, it will run ~$1.10/hr for the same size.

{/*

## Getting in to the slither.io Top 10

Anyone that understands modern gaming will laugh at this, but my initial test for these cloud gaming setups was [slither.io](https://slither.io). If you are not familiar with it, I recommend you do not check it out if you are at all inclined to getting addicted to blinky lights like I am.

Slither.io is a simple, visual, somewhat twitchy, game that can be played in a browser. It uses WebGL (thus will usually use GPU if everything is configured correctly). On my laptop, it's playable, but is a little jerky, especially at larger window sizes or fullscreen. I'm not really sure why it's jerky because it's not a CPU/GPU demanding game. (More on that below.) It's smoother on my iPad (as an app), where I suspect any perceived hiccups there are due to network lag and/or server overloads.

I can usually get in to the top 10 if I am dedicated to it, but it often takes a few attempts when playing on the laptop. When I die, most of the time it's due to lag or hiccups. What I noticed is that once I had the cloud gaming setups correct (i.e. Using Parsec), Slither.io was very smooth with almost no lags or hiccups. I could get in to the top 10 much more quickly and consistently. When I died, it was more often (okay... always) my own fault. So while very simple, it opened my eyes to the benefits of a more powerful gaming setup. The benefits can come from a combination of better CPU, GPU, and network.

Interestingly, having a faster network between the game client and game servers seemed to be more important than the network between my streaming client and cloud game server. My assumption is that overall improvement hides the additional round-trip latency that a cloud gaming setup introduces.

I did also try with [X-Plane 11](https://www.x-plane.com/) ...a slightly more demanding game.

## Aside: Why does my laptop hiccup on Slither?

I've never been able to figure out why my laptop does not run slither.io smoothly and with no effort. It's playable, but _feels_ like it's stuttering at times and working harder than it should (evidenced by the fans kicking on). Thinking about it, there's an insane number of potential culprits and no easy way to figure it out for certain. I remember reading, I think in the early 2000s, a relevant article in PC Magazine by [John Dvorak](https://en.wikipedia.org/wiki/John_C._Dvorak). The premise (written in his cocky style) was around the consequences of adding multiple CPUs, which were a relatively new thing at the time in personal computers. He suggested that having multiple CPUs only meant processes could hang, and software could get buggier, without anyone realizing it. I have often though about that.

My current laptop is a Dell Precision 5520. I've installed Windows 10 from scratch at least twice. It has two graphic cards:

- Intel Graphics 630 HD (onboard)
- NVIDIA Quadro M1200 (discrete)

The Quadro M1200 is not known as a powerful gaming card, but it should be more than sufficient for something like slither.io. For that matter, even the Intel 630 HD should be sufficient.

I know how to switch between the cards (which is a topic in itself...I suspect most people with these setups never actually use the discrete video card. It simply didn't work as received from Dell and it can be difficult to tell when it's actually being used). Lately I've been using the discrete card for Chrome. Chrome's implementation of WebGL makes use of hardware support. Point being in all of this... there is no reason slither.io shouldn't be super smooth graphically on my laptop. It shouldn't even require the fans to spin up, imo.

I ordered the 4k display (3840x2160) for this laptop, but I generally use an attached 4k monitor via HDMI connection. This means the graphic bits are generally getting pushed out to two 4k displays simultaneously, although I only ever game on one at a time.

I'm not sure the actual hiccups are even graphics related, at least directly. That's where things start getting complex. Is it graphics card related? Graphics driver related? Windows 10 related? Is it Chrome? Is it network bandwidth? My network adapter? My network router? Motherboard limitations? Is it my USB hub? I started thinking through all the possible layers and came up with this:

- Slither.io Code
- Perhaps there is something in the code itself that triggers poor handling on my laptop for whatever reason. Unlikely, but possible.
- Browser (Chrome/Firefox/Etc)
- JavaScript Engine
- WebGL Implementation
- Windows 10
- NVidia Driver
- Onboard vs. discrete pipeline
  - Software switch previously handled by nVidia, now handled by Windows 10
- Compositor
  - A complex subject, but at some point Windows must composite graphics from various sources for rendering to the displays.
- Video/Graphics bus
- I don't know how the bus is handled between onboard and discrete in the motherboard. At some point, there has to be choke point as things get composited and go out to the displays. In the past, this technology was culprit for many problems, and in older laptops I would disable it in bios to only use onboard _or_ discrete at any given time. Reboots required.
- Attached Screen vs External Screen
- There are different pathways for the onboard screen and external displays. My 4k external display is currently attached via HDMI port. In the past, I have had situations were graphics card performance on external display was not the same as graphics card performance on attached display. Similarly, differences in performance when connecting via HDMI vs USB-C.
- Motherboard
- Minimally, modern laptops impair performance when the heat starts to rise.
- Virtualization
- I am often running mulitple WSL2 instances, Docker containers, etc. I expect they want some of that sweet CPU periodically too. I've read that next version of WSL2 is going to allow direct access to the GPU. That will be another level of complexity.
- Motherboard USB Controller(s)
- Important to consider because most modern laptops no longer have onboard ethernet ports. Mine included. (Thanks Apple. :|) As a result, I have to use an external USB ethernet dongle for wired network. The motherboard USB controller only has so much bandwidth and in the past I have seen cases where simply plugging in to different USB ports (assuming different internal controllers) made a difference in performance. None of this is ever documented.
- Wifi
- If not using wired network, then the wifi hardware comes in to play. And in my experience, everything about wifi is non-deterministic. Goodluck hunting down the root cause of unreliable, slow, or randomly intermittent wifi problems. It can be nearly impossible.
- USB Network Dongle
- I now have five different ethernet dongles. Not all of them work. Not all of them are reliable. There is no way to know if the one I'm currently using doesn't cause network slowness or hiccups.
- USB Hub
- USB hubs are considered commodities. And yet, I have multiple because not all of them work. Not all of them are reliable. There is no way to know if the one I'm currently using doesn't cause network slowness or hiccups. I hate the state of this industry right now.
- My preference is to use a combined hub that provides powered USB ports and a built-in gigabit ethernet port. With one of these I've tried, I noticed that while trying to use network at same time as an attached 7200rpm harddrive, the network would simply pause after a few megabytes. That shouldn't happen.
- Network Router
- Again, one might simply assume that a high end network router just works. And yet, I have found recently with my latest $300 router, that simply restarting it will sometimes cause my networks (wired and wifi) to perform better. It also crashes every few weeks.
- Network Components
- I have a 5-port gigabit ethernet switch on my network. A true commodity device, right? I have had to unplug/replug to reset it twice after it seemingly locked up. I bought this one after the previous one had 3 failing ports. Any chance the switch is causing some intermittent network problems? Unlikely, but...
- Internet Service Provider Hardware
- I always buy my own modems because the ones ISPs provide are so terrible. But, who is to say the one I bought is much better? I bought it at Walmart. The ISP constantly upgrades and reconfigures it without my knowledge. Perhaps it introduces network issues?
- Internet Service
- A complex topic with one hundred other potential points of random failure across the Internet.
- Game Servers
- When a multiplayer game is running slow or there's lag, it could simply be that the game providers servers/networks are overloaded. Or it depending on how game is coded, it could even be one or more of the other players (each with the complete stack of potential problem areas listed above).

...so when experiencing lag or poor performance, which of the above items is the reason? I didn't even mention the actual CPU/GPU power.
*/}
